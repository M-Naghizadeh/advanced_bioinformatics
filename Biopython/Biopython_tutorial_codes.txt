
 import Bio
 print(Bio.__version__)

---------

 from Bio.Seq import Seq

 my_seq = Seq("AGTACACTGGT")
 my_seq

 print(my_seq)

 my_seq

 my_seq.complement()

 my_seq.reverse_complement()

---------

 from Bio import SeqIO

 for seq_record in SeqIO.parse("ls_orchid.fasta", "fasta"):
 
     print(seq_record.id)

     print(repr(seq_record.seq))

     print(len(seq_record))

 from Bio import SeqIO

 for seq_record in SeqIO.parse("ls_orchid.gbk", "genbank"):

 from Bio.Seq import Seq

 my_seq = Seq("GATCG")

 for index, letter in enumerate(my_seq):

 print(len(my_seq))

 print(my_seq[0]) #first letter

 print(my_seq[2]) #third letter
 print(my_seq[-1]) #last letter
 from Bio.Seq import Seq
 "AAAA".count("AA")
 Seq("AAAA").count("AA")
 from Bio.Seq import Seq
 my_seq = Seq("GATCGATGGGCCTATATAGGATCGAAAATCGC")
 len(my_seq)
 my_seq.count("G")
 100 * float(my_seq.count("G") + my_seq.count("C")) / len(my_seq)
 from Bio.Seq import Seq
 from Bio.SeqUtils import GC
 my_seq = Seq("GATCGATGGGCCTATATAGGATCGAAAATCGC")
 GC(my_seq)
 from Bio.Seq import Seq
 my_seq = Seq("GATCGATGGGCCTATATAGGATCGAAAATCGC")
 my_seq[4:12]
 my_seq[0::3]
 my_seq[1::3]
 my_seq[2::3]
 my_seq[::-1]
 str(my_seq)
 print(my_seq)
 fasta_format_string = "Name\n%s\n" % my_seq
 print(fasta_format_string)
Name
<BLANKLINE
 from Bio.Seq import Seq
 protein_seq = Seq("EVRNAK")
 dna_seq = Seq("ACGT")
 protein_seq + dna_seq
 from Bio.Seq import Seq
 list_of_seqs = [Seq("ACGT"), Seq("AACC"), Seq("GGTT")]
 concatenated = Seq("")
 for s in list_of_seqs:
 concatenated
 from Bio.Seq import Seq
 contigs = [Seq("ATG"), Seq("ATCCCG"), Seq("TTGCA")]
 spacer = Seq("N"*10)
 spacer.join(contigs)
 from Bio.Seq import Seq
 dna_seq = Seq("acgtACGT")
 dna_seq
 dna_seq.upper()
 dna_seq.lower()
 "GTAC" in dna_seq
 "GTAC" in dna_seq.upper()
 from Bio.Seq import Seq
 my_seq = Seq("GATCGATGGGCCTATATAGGATCGAAAATCGC")
 my_seq
 my_seq.complement()
 my_seq.reverse_complement()
 my_seq[::-1]
 from Bio.Seq import Seq
 protein_seq = Seq("EVRNAK")
 protein_seq.complement()
 from Bio.Seq import Seq
 coding_dna = Seq("ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG")
 coding_dna
 template_dna = coding_dna.reverse_complement()
 template_dna
 coding_dna
 messenger_rna = coding_dna.transcribe()
 messenger_rna
 template_dna.reverse_complement().transcribe()
 from Bio.Seq import Seq
 messenger_rna = Seq("AUGGCCAUUGUAAUGGGCCGCUGAAAGGGUGCCCGAUAG")
 messenger_rna
 messenger_rna.back_transcribe()
 from Bio.Seq import Seq
 messenger_rna = Seq("AUGGCCAUUGUAAUGGGCCGCUGAAAGGGUGCCCGAUAG")
 messenger_rna
 messenger_rna.translate()
 from Bio.Seq import Seq
 coding_dna = Seq("ATGGCCATTGTAATGGGCCGCTGAAAGGGTGCCCGATAG")
 coding_dna
 coding_dna.translate()
 coding_dna.translate(table="Vertebrate Mitochondrial")
 coding_dna.translate(table=2)
 coding_dna.translate()
 coding_dna.translate(to_stop=True)
 coding_dna.translate(table=2)
 coding_dna.translate(table=2, to_stop=True)
 coding_dna.translate(table=2, stop_symbol="@")
 from Bio.Seq import Seq
 gene = Seq("GTGAAAAAGATGCAATCTATCGTACTCGCACTTTCCCTGGTTCTGGTCGCTCCCATGGCA"
 gene.translate(table="Bacterial")
 gene.translate(table="Bacterial", to_stop=True)
 gene.translate(table="Bacterial", cds=True)
 from Bio.Data import CodonTable
 standard_table = CodonTable.unambiguous_dna_by_name["Standard"]
 mito_table = CodonTable.unambiguous_dna_by_name["Vertebrate Mitochondrial"]
 from Bio.Data import CodonTable
 standard_table = CodonTable.unambiguous_dna_by_id[1]
 mito_table = CodonTable.unambiguous_dna_by_id[2]
 print(standard_table)
 print(mito_table)
 mito_table.stop_codons
 mito_table.start_codons
 mito_table.forward_table["ACG"]
 from Bio.Seq import Seq
 seq1 = Seq("ACGT")
 "ACGT" == seq1
 seq1 == "ACGT"
 from Bio.Seq import Seq
 my_seq = Seq("GCCATTGTAATGGGCCGCTGAAAGGGTGCCCGA")
 my_seq[5] = "G"
 mutable_seq = my_seq.tomutable()
 mutable_seq
 from Bio.Seq import MutableSeq
 mutable_seq = MutableSeq("GCCATTGTAATGGGCCGCTGAAAGGGTGCCCGA")
 mutable_seq
 mutable_seq[5] = "C"
 mutable_seq
 mutable_seq.remove("T")
 mutable_seq
 mutable_seq.reverse()
 mutable_seq
 new_seq = mutable_seq.toseq()
 new_seq
 from Bio.Seq import UnknownSeq
 unk = UnknownSeq(20)
 unk
 print(unk)
 len(unk)
 from Bio.Seq import UnknownSeq
 unk_dna = UnknownSeq(20, character="N")
 unk_dna
 print(unk_dna)
 unk_dna
 unk_dna.complement()
 unk_dna.reverse_complement()
 unk_dna.transcribe()
 unk_protein = unk_dna.translate()
 unk_protein
 print(unk_protein)
 len(unk_protein)
 from Bio.Seq import reverse_complement, transcribe, back_transcribe, transla
 my_string = "GCTGTTATGGGTCGTTGGAAGGGTGGTCGTGCTGCTGGTTAG"
 reverse_complement(my_string)
 transcribe(my_string)
 back_transcribe(my_string)
 translate(my_string)
 from Bio.SeqRecord import SeqRecord
 help(SeqRecord)
 from Bio.Seq import Seq
 simple_seq = Seq("GATC")
 from Bio.SeqRecord import SeqRecord
 simple_seq_r = SeqRecord(simple_seq)
 simple_seq_r.id
'<unknown id'
 simple_seq_r.id = "AC12345"
 simple_seq_r.description = "Made up sequence I wish I could write a paper ab
 print(simple_seq_r.description)
 simple_seq_r.seq
 from Bio.Seq import Seq
 simple_seq = Seq("GATC")
 from Bio.SeqRecord import SeqRecord
 simple_seq_r = SeqRecord(simple_seq, id="AC12345")
 simple_seq_r.annotations["evidence"] = "None. I just made it up."
 print(simple_seq_r.annotations)
 print(simple_seq_r.annotations["evidence"])
 simple_seq_r.letter_annotations["phred_quality"] = [40, 40, 38, 30]
 print(simple_seq_r.letter_annotations)
 print(simple_seq_r.letter_annotations["phred_quality"])
gi|45478711|ref|NC_005816.1| Yersinia pestis biovar Microtus ... pPCP1, complet
 from Bio import SeqIO
 record = SeqIO.read("NC_005816.fna", "fasta")
 record
 record.seq
 record.id
 record.name
 record.description
Yersinia pestis biovar Microtus str. 91001 plasmid pPCP1
 record.dbxrefs
 record.annotations
 record.letter_annotations
 record.features
 from Bio import SeqIO
 record = SeqIO.read("NC_005816.gb", "genbank")
 record
 record.seq
 record.id
 record.name
 record.description
 record.letter_annotations
 len(record.annotations)
 record.annotations["source"]
 record.dbxrefs
 len(record.features)
          fuzzy or not. For instance, 5, 20, <100 and 200 are all
          GenBank as `13', and like BeforePosition, you get the boundary
 from Bio import SeqFeature
 start_pos = SeqFeature.AfterPosition(5)
 end_pos = SeqFeature.BetweenPosition(9, left=8, right=9)
 my_location = SeqFeature.FeatureLocation(start_pos, end_pos)
 print(my_location)
[5:(8^9)]
 my_location.start
 print(my_location.start)
5
 my_location.end
 print(my_location.end)
 int(my_location.start)
 int(my_location.end)
 my_location.nofuzzy_start
 my_location.nofuzzy_end
 exact_location = SeqFeature.FeatureLocation(5, 9)
 print(exact_location)
 exact_location.start
 int(exact_location.start)
 exact_location.nofuzzy_start
 from Bio import SeqIO
 my_snp = 4350
 record = SeqIO.read("NC_005816.gb", "genbank")
 for feature in record.features:
 from Bio.Seq import Seq
 from Bio.SeqFeature import SeqFeature, FeatureLocation
 seq = Seq("ACCGAGACGGCAAAGGCTAGCATAGGTATGAGACTTCCTTCCTGCCAGTGCTGAGGAACTGGGAG
 feature = SeqFeature(FeatureLocation(5, 18), type="gene", strand=-1)
 feature_seq = seq[feature.location.start:feature.location.end].reverse_compl
 print(feature_seq)
 feature_seq = feature.extract(seq)
 print(feature_seq)
 print(len(feature_seq))
 print(len(feature))
 print(len(feature.location))
 from Bio.Seq import Seq
 from Bio.SeqRecord import SeqRecord
 record1 = SeqRecord(Seq("ACGT"), id="test")
 record2 = SeqRecord(Seq("ACGT"), id="test")
 record1 == record2
 record1 == record2  # on old versions of Biopython!
 record1 == record2
 record1.id == record2.id
 record1.seq == record2.seq
 from Bio.Seq import Seq
 from Bio.SeqRecord import SeqRecord
 record = SeqRecord(
 print(record.format("fasta"))
gi|14150838|gb|AAK54648.1|AF376133_1 chalcone synthase [Cucumis sativus]
<BLANKLINE
 from Bio import SeqIO
 record = SeqIO.read("NC_005816.gb", "genbank")
 record
 len(record)
 len(record.features)
 print(record.features[20])
<BLANKLINE
 print(record.features[21])
<BLANKLINE
 sub_record = record[4300:4800]
 sub_record
 len(sub_record)
 len(sub_record.features)
 print(sub_record.features[0])
<BLANKLINE
 print(sub_record.features[1])
<BLANKLINE
 sub_record.annotations
 sub_record.dbxrefs
 sub_record.id
 sub_record.name
 sub_record.description
 sub_record.description = "Yersinia pestis biovar Microtus str. 91001 plasmid
 print(sub_record.format("genbank"))
 from Bio import SeqIO
 record = next(SeqIO.parse("example.fastq", "fastq"))
 len(record)
 print(record.seq)
 print(record.letter_annotations["phred_quality"])
 left = record[:20]
 print(left.seq)
 print(left.letter_annotations["phred_quality"])
 right = record[21:]
 print(right.seq)
 print(right.letter_annotations["phred_quality"])
 edited = left + right
 len(edited)
 print(edited.seq)
 print(edited.letter_annotations["phred_quality"])
 edited = record[:20] + record[21:]
 from Bio import SeqIO
 record = SeqIO.read("NC_005816.gb", "genbank")
 record
 len(record)
 len(record.features)
 record.dbxrefs
 record.annotations.keys()
 shifted = record[2000:] + record[:2000]
 shifted
 len(shifted)
 len(shifted.features)
 shifted.dbxrefs
 shifted.annotations.keys()
 shifted.dbxrefs = record.dbxrefs[:]
 shifted.annotations = record.annotations.copy()
 shifted.dbxrefs
 shifted.annotations.keys()
 from Bio import SeqIO
 record = SeqIO.read("NC_005816.gb", "genbank")
 print("%s %i %i %i %i" % (record.id, len(record), len(record.features), len(
 rc = record.reverse_complement(id="TESTING")
 print("%s %i %i %i %i" % (rc.id, len(rc), len(rc.features), len(rc.dbxrefs),
 from Bio import SeqIO
 help(SeqIO)
 from Bio import SeqIO
 identifiers = [seq_record.id for seq_record in SeqIO.parse("ls_orchid.gbk",
 identifiers
 print(first_record.annotations["source"])
 print(first_record.annotations["organism"])
gi|2765658|emb|Z78533.1|CIZ78533 C.irapeanum 5.8S rRNA gene and ITS1 and ITS2 D
 from Bio import SeqIO
 record_iterator = SeqIO.parse("ls_orchid.fasta", "fasta")
 first_record = next(record_iterator)
 first_record.id
 first_record.id = "new_id"
 first_record.id
 from Bio import SeqIO
 record_iterator = SeqIO.parse("ls_orchid.fasta", "fasta")
 first_record = next(record_iterator)
 first_record.id = "new_id"
 first_record.description = first_record.id + " " + "desired new description"
 print(first_record.format("fasta")[:200])
new_id desired new description
 from Bio import SeqIO
 print(sum(len(r) for r in SeqIO.parse("ls_orchid.gbk", "gb")))
 from Bio import SeqIO
 with open("ls_orchid.gbk") as handle:
 from Bio import SeqIO
 handle = open("ls_orchid.gbk")
 print(sum(len(r) for r in SeqIO.parse(handle, "gb")))
 handle.close()
 import gzip
 from Bio import SeqIO
 with gzip.open("ls_orchid.gbk.gz", "rt") as handle:
 import bz2
 from Bio import SeqIO
 with bz2.open("ls_orchid.gbk.bz2", "rt") as handle:
 from Bio import SeqIO
 orchid_dict = SeqIO.to_dict(SeqIO.parse("ls_orchid.gbk", "genbank"))
 len(orchid_dict)
 list(orchid_dict.keys())
 list(orchid_dict.values()) #lots of output!
 seq_record = orchid_dict["Z78475.1"]
 print(seq_record.description)
 seq_record.seq
    e.g. "gi|2765613|emb|Z78488.1|PTZ78488" - "Z78488.1"
 print(orchid_dict.keys())
 from Bio import SeqIO
 from Bio.SeqUtils.CheckSum import seguid
 seguid_dict = SeqIO.to_dict(SeqIO.parse("ls_orchid.gbk", "genbank"),
 record = seguid_dict["MN/s0q9zDoCVEEc+k/IFwCNF2pY"]
 print(record.id)
 print(record.description)
 from Bio import SeqIO
 orchid_dict = SeqIO.index("ls_orchid.gbk", "genbank")
 len(orchid_dict)
 orchid_dict.keys()
 seq_record = orchid_dict["Z78475.1"]
 print(seq_record.description)
 seq_record.seq
 orchid_dict.close()
 from Bio import SeqIO
 orchid_dict = SeqIO.index("ls_orchid.fasta", "fasta")
 len(orchid_dict)
 orchid_dict.keys()
    e.g. "gi|2765613|emb|Z78488.1|PTZ78488" - "Z78488.1"
 from Bio import SeqIO
 orchid_dict = SeqIO.index("ls_orchid.fasta", "fasta", key_function=get_acc)
 print(orchid_dict.keys())
 from Bio import SeqIO
 uniprot = SeqIO.index("uniprot_sprot.dat", "swiss")
 with open("selected.dat", "wb") as out_handle:
 import glob
 from Bio import SeqIO
 files = glob.glob("gbvrl*.seq")
 print("%i files to index" % len(files))
 gb_vrl = SeqIO.index_db("gbvrl.idx", files, "genbank")
 print("%i sequences indexed" % len(gb_vrl))
 print(gb_vrl["AB811634.1"].description)
 print(gb_vrl.get_raw("AB811634.1"))
 from Bio import SeqIO
 orchid_dict = SeqIO.index("ls_orchid.gbk", "genbank")
 len(orchid_dict)
 orchid_dict.close()
$ bgzip -c ls_orchid.gbk  ls_orchid.gbk.bgz
 from Bio import SeqIO
 orchid_dict = SeqIO.index("ls_orchid.gbk.bgz", "genbank")
 len(orchid_dict)
 orchid_dict.close()
 from Bio import SeqIO
 orchid_dict = SeqIO.index_db("ls_orchid.gbk.bgz.idx", "ls_orchid.gbk.bgz", "
 len(orchid_dict)
 orchid_dict.close()
gi|14150838|gb|AAK54648.1|AF376133_1 chalcone synthase [Cucumis sativus]
gi|13919613|gb|AAK33142.1| chalcone synthase [Fragaria vesca subsp. bracteata]
gi|13925890|gb|AAK49457.1| chalcone synthase [Nicotiana tabacum]
YAL068C-7235.2170 Putative promoter sequence
YAL068C-7235.2170 Putative promoter sequence
 from Bio import SeqIO
 help(SeqIO.convert)
 from Bio import SeqIO
 for record in SeqIO.parse("ls_orchid.gbk", "genbank"):
 from Bio import SeqIO
 records = [rec.reverse_complement(id="rc_"+rec.id, description = "reverse co
 len(records)
 records = [rec.reverse_complement(id="rc_"+rec.id, description = "reverse co
 len(records)
 records = (rec.reverse_complement(id="rc_"+rec.id, description = "reverse co
 from Bio import SeqIO
 records = (rec.reverse_complement(id="rc_"+rec.id, description = "reverse co
 SeqIO.write(records, "rev_comp.fasta", "fasta")
        if len(record)  100:
records = (rec for rec in SeqIO.parse("ls_orchid.gbk", "genbank") if len(rec) 
   tuple of two strings, the title line (everything after the  character)
 from Bio.SeqIO.FastaIO import SimpleFastaParser
 count = 0
 total_len = 0
 with open("ls_orchid.fasta") as in_handle:
 print("%i records with total sequence length %i" % (count, total_len))
out_handle.write("%s\n%s\n" % (title, seq))
 from Bio.SeqIO.QualityIO import FastqGeneralIterator
 count = 0
 total_len = 0
 with open("example.fastq") as in_handle:
 print("%i records with total sequence length %i" % (count, total_len))
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 print(alignment)
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 print("Alignment length %i" % alignment.get_alignment_length())
 for record in alignment:
 for record in alignment:
 for record in alignment:
COATB_BPIKE/30-81
Q9T0Q8_BPIKE/1-52
COATB_BPI22/32-83
COATB_BPM13/24-72
COATB_BPZJ2/1-49
Q9T0Q9_BPFD/1-49
COATB_BPIF1/22-73
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.faa", "fasta")
 print(alignment)
 from Bio import AlignIO
 help(AlignIO)
 from Bio import AlignIO
 alignments = AlignIO.parse("resampled.phy", "phylip")
 for alignment in alignments:
 from Bio import AlignIO
 alignments = list(AlignIO.parse("resampled.phy", "phylip"))
 last_align = alignments[-1]
 first_align = alignments[0]
Alpha
Beta
Gamma
Alpha
Beta
Gamma
Alpha
Beta
Alpha
Gamma
Alpha
Delta
Alpha
XXX
Alpha
YYY
Alpha
ZZZ
 for alignment in AlignIO.parse(handle, "fasta", seq_count=2):
 from Bio.Seq import Seq
 from Bio.SeqRecord import SeqRecord
 from Bio.Align import MultipleSeqAlignment
 align1 = MultipleSeqAlignment(
 align2 = MultipleSeqAlignment(
 align3 = MultipleSeqAlignment(
 my_alignments = [align1, align2, align3]
 from Bio import AlignIO
 AlignIO.write(my_alignments, "my_example.phy", "phylip")
 from Bio import AlignIO
 count = AlignIO.convert("PF05371_seed.sth", "stockholm", "PF05371_seed.aln",
 print("Converted %i alignments" % count)
 from Bio import AlignIO
 alignments = AlignIO.parse("PF05371_seed.sth", "stockholm")
 count = AlignIO.write(alignments, "PF05371_seed.aln", "clustal")
 print("Converted %i alignments" % count)
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 AlignIO.write([alignment], "PF05371_seed.aln", "clustal")
 from Bio import AlignIO
 AlignIO.convert("PF05371_seed.sth", "stockholm", "PF05371_seed.phy", "phylip
 from Bio import AlignIO
 AlignIO.convert("PF05371_seed.sth", "stockholm", "PF05371_seed.phy", "phylip
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 name_mapping = {}
 for i, record in enumerate(alignment):
 print(name_mapping)
 AlignIO.write([alignment], "PF05371_seed.phy", "phylip")
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 print(format(alignment, "clustal"))
 from io import StringIO
 from Bio import AlignIO
 alignments = AlignIO.parse("PF05371_seed.sth", "stockholm")
 out_handle = StringIO()
 AlignIO.write(alignments, out_handle, "clustal")
 clustal_data = out_handle.getvalue()
 print(clustal_data)
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 print("Number of rows: %i" % len(alignment))
 for record in alignment:
 print(alignment)
 print(alignment[3:7])
 print(alignment[2, 6])
 print(alignment[2].seq[6])
 print(alignment[:, 6])
 print(alignment[3:6, :6])
 print(alignment[:, :6])
 print(alignment[:, 6:9])
 print(alignment[:, 9:])
 edited = alignment[:, :6] + alignment[:, 9:]
 print(edited)
 edited.sort()
 print(edited)
 import numpy as np
 from Bio import AlignIO
 alignment = AlignIO.read("PF05371_seed.sth", "stockholm")
 align_array = np.array([list(rec) for rec in alignment], np.character)
 print("Array shape %i by %i" % align_array.shape)
 align_array = np.array([list(rec) for rec in alignment], np.character, order
 from Bio.Seq import Seq
 from Bio.SeqRecord import SeqRecord
 from Bio.Align import MultipleSeqAlignment
 alignment = MultipleSeqAlignment(
 print(alignment)
 substitutions = alignment.substitutions
 print(substitutions)
<BLANKLINE
 m = substitutions.select("ATCG")
 print(m)
<BLANKLINE
 import Bio.Align.Applications
 dir(Bio.Align.Applications) # doctest:+ELLIPSIS
 from Bio.Align.Applications import ClustalwCommandline
 help(ClustalwCommandline)
 from Bio.Align.Applications import ClustalwCommandline
 cline = ClustalwCommandline("clustalw2", infile="opuntia.fasta")
 print(cline)
 import os
 from Bio.Align.Applications import ClustalwCommandline
 clustalw_exe = r"C:\Program Files\new clustal\clustalw2.exe"
 clustalw_cline = ClustalwCommandline(clustalw_exe, infile="opuntia.fasta")
 assert os.path.isfile(clustalw_exe), "Clustal W executable missing"
 stdout, stderr = clustalw_cline()
 from Bio import AlignIO
 align = AlignIO.read("opuntia.aln", "clustal")
 print(align)
 from Bio import Phylo
 tree = Phylo.read("opuntia.dnd", "newick")
 Phylo.draw_ascii(tree)
<BLANKLINE
 from Bio.Align.Applications import MuscleCommandline
 help(MuscleCommandline)
 from Bio.Align.Applications import MuscleCommandline
 cline = MuscleCommandline(input="opuntia.fasta", out="opuntia.txt")
 print(cline)
 from Bio.Align.Applications import MuscleCommandline
 cline = MuscleCommandline(input="opuntia.fasta", out="opuntia.aln", clw=True
 print(cline)
 from Bio.Align.Applications import MuscleCommandline
 cline = MuscleCommandline(input="opuntia.fasta", out="opuntia.aln", clwstric
 print(cline)
 from Bio.Align.Applications import MuscleCommandline
 muscle_cline = MuscleCommandline(input="opuntia.fasta")
 print(muscle_cline)
 from Bio.Align.Applications import MuscleCommandline
 muscle_cline = MuscleCommandline(input="opuntia.fasta")
 stdout, stderr = muscle_cline()
 from io import StringIO
 from Bio import AlignIO
 align = AlignIO.read(StringIO(stdout), "fasta")
 print(align)
 import subprocess
 from Bio.Align.Applications import MuscleCommandline
 muscle_cline = MuscleCommandline(input="opuntia.fasta")
 child = subprocess.Popen(str(muscle_cline),
 from Bio import AlignIO
 align = AlignIO.read(child.stdout, "fasta")
 print(align)
 from Bio import SeqIO
 records = (r for r in SeqIO.parse("opuntia.fasta", "fasta") if len(r) < 900)
 from Bio.Align.Applications import MuscleCommandline
 muscle_cline = MuscleCommandline(clwstrict=True)
 print(muscle_cline)
 import subprocess
 import sys
 child = subprocess.Popen(str(cline),
 SeqIO.write(records, child.stdin, "fasta")
 child.stdin.close()
 from Bio import AlignIO
 align = AlignIO.read(child.stdout, "clustal")
 print(align)
 from Bio import SeqIO
 records = (r for r in SeqIO.parse("opuntia.fasta", "fasta") if len(r) < 900)
 from io import StringIO
 handle = StringIO()
 SeqIO.write(records, handle, "fasta")
 data = handle.getvalue()
 stdout, stderr = muscle_cline(stdin=data)
 from Bio import AlignIO
 align = AlignIO.read(StringIO(stdout), "clustal")
 print(align)
HBA_HUMAN
HBB_HUMAN
 from Bio.Emboss.Applications import NeedleCommandline
 needle_cline = NeedleCommandline(asequence="alpha.faa", bsequence="beta.faa"
 print(needle_cline)
 from Bio.Emboss.Applications import NeedleCommandline
 needle_cline = NeedleCommandline(r"C:\EMBOSS\needle.exe",
 from Bio.Emboss.Applications import NeedleCommandline
 help(NeedleCommandline)
 from Bio.Emboss.Applications import NeedleCommandline
 needle_cline = NeedleCommandline()
 needle_cline.asequence="alpha.faa"
 needle_cline.bsequence="beta.faa"
 needle_cline.gapopen=10
 needle_cline.gapextend=0.5
 needle_cline.outfile="needle.txt"
 print(needle_cline)
 print(needle_cline.outfile)
 stdout, stderr = needle_cline()
 print(stdout + stderr)
 from Bio import AlignIO
 align = AlignIO.read("needle.txt", "emboss")
 print(align)
   versions 1.67) so that for short sequences (global alignments: ~2000
 from Bio import pairwise2
 from Bio import SeqIO
 seq1 = SeqIO.read("alpha.faa", "fasta")
 seq2 = SeqIO.read("beta.faa", "fasta")
 alignments = pairwise2.align.globalxx(seq1.seq, seq2.seq)
 len(alignments)
 print(alignments[0]) # doctest:+ELLIPSIS
 print(pairwise2.format_alignment(*alignments[0])) # doctest:+ELLIPSIS
<BLANKLINE
 alignments = pairwise2.align.globalxx(sequenceA=seq1.seq, sequenceB=seq2.seq
 from Bio import pairwise2
 from Bio import SeqIO
 from Bio.Align import substitution_matrices
 blosum62 = substitution_matrices.load("BLOSUM62")
 seq1 = SeqIO.read("alpha.faa", "fasta")
 seq2 = SeqIO.read("beta.faa", "fasta")
 alignments = pairwise2.align.globalds(seq1.seq, seq2.seq, blosum62, -10, -0.
 len(alignments)
 print(pairwise2.format_alignment(*alignments[0]))
 from Bio import pairwise2
 from Bio.Align import substitution_matrices
 blosum62 = substitution_matrices.load("BLOSUM62")
 alignments = pairwise2.align.localds("LSPADKTNVKAA", "PEEKSAV", blosum62, -1
 print(pairwise2.format_alignment(*alignments[0]))
<BLANKLINE
 from Bio import pairwise2
 from Bio.Align import substitution_matrices
 blosum62 = substitution_matrices.load("BLOSUM62")
 alignments = pairwise2.align.localds("LSPADKTNVKAA", "PEEKSAV", blosum62, -1
 print(pairwise2.format_alignment(*alignments[0], full_sequences=True))
<BLANKLINE
   positive score (0). Thus, pairwise2 may return no alignments if no
   score 0 has been obtained. Also, pairwise2 will not report alignments
 from Bio import pairwise2
 from Bio.Align import substitution_matrices
 blosum62 = substitution_matrices.load("BLOSUM62")
 alignments = pairwise2.align.localds("LSSPADKTNVKKAA", "DDPEEKSAVNN", blosum
 print(pairwise2.format_alignment(*alignments[0]))
<BLANKLINE
 alignments = pairwise2.align.localms("AGAACT", "GAC", 5, -4, -2, -0.5)
 print(pairwise2.format_alignment(*alignments[0]))
<BLANKLINE
 from Bio import Align
 aligner = Align.PairwiseAligner()
 aligner = Align.PairwiseAligner(match_score=1.0)
 aligner.match_score = 1.0
 seq1 = "GAACT"
 seq2 = "GAT"
 score = aligner.score(seq1, seq2)
 score
 alignments = aligner.align(seq1, seq2)
 for alignment in alignments:
<BLANKLINE
<BLANKLINE
 aligner.mode = 'local'
 seq1 = "AGAACTC"
 seq2 = "GAACT"
 score = aligner.score(seq1, seq2)
 score
 alignments = aligner.align(seq1, seq2)
 for alignment in alignments:
<BLANKLINE
 print(aligner)
<BLANKLINE
 aligner.algorithm
 aligner.epsilon
 from Bio import Align
 aligner = Align.PairwiseAligner()
 aligner.match_score
 aligner.mismatch_score
 score = aligner.score("ACGT","ACAT")
 print(score)
 aligner.match_score = 1.0
 aligner.mismatch_score = -2.0
 aligner.gap_score = -2.5
 score = aligner.score("ACGT","ACAT")
 print(score)
 score = aligner.score("ACGT","ACXT")
 print(score)
 from Bio.Align import substitution_matrices
 substitution_matrices.load()  #doctest: +ELLIPSIS
 matrix = substitution_matrices.load("BLOSUM62")
 print(matrix)  #doctest: +ELLIPSIS
 aligner.substitution_matrix = matrix
 score = aligner.score("ACDQ", "ACDQ")
 score
 score = aligner.score("ACDQ", "ACNQ")
 score
 matrix['D','X']
 score = aligner.score("ACDQ", "ACXQ")
 score
 from Bio import Align
 aligner = Align.PairwiseAligner()
 def my_gap_score_function(start, length):
 aligner.query_gap_score = my_gap_score_function
 alignments = aligner.align("AACTT", "AATT")
 for alignment in alignments:
<BLANKLINE
<BLANKLINE
<BLANKLINE
<BLANKLINE
 from Bio import Align
 aligner = Align.PairwiseAligner()
 alignments = aligner.align("AAA", "AA")
 len(alignments)
 from Bio import Align
 aligner = Align.PairwiseAligner()
 alignments = aligner.align("AAA", "AA")
 print(alignments[2])
<BLANKLINE
 print(alignments[0])
<BLANKLINE
 for alignment in alignments:
 from Bio import Align
 aligner = Align.PairwiseAligner()
 alignments = aligner.align("AAA", "AA")
 for alignment in alignments:
<BLANKLINE
<BLANKLINE
<BLANKLINE
 for alignment in alignments:
<BLANKLINE
<BLANKLINE
<BLANKLINE
 alignments = list(alignments)
 print(alignments.score)
 from Bio import Align
 aligner = Align.PairwiseAligner()
 seq1 = "GAACT"
 seq2 = "GAT"
 alignments = aligner.align(seq1, seq2)
 alignment = alignments[0]
 alignment # doctest: +SKIP
<Bio.Align.PairwiseAlignment object at 0x10204d250
 alignment.score
 alignment.target
 alignment.query
 print(alignment)
<BLANKLINE
 format(alignment, 'psl')
 alignment.aligned
 alignment = alignments[1]
 print(alignment)
<BLANKLINE
 alignment.aligned
 aligner.mismatch_score = -10
 alignments = aligner.align("AAACAAA", "AAAGAAA")
 len(alignments)
 print(alignments[0])
<BLANKLINE
 alignments[0].aligned
 print(alignments[1])
<BLANKLINE
 alignments[1].aligned
 from Bio import Align
 from Bio import SeqIO
 seq1 = SeqIO.read("alpha.faa", "fasta")
 seq2 = SeqIO.read("beta.faa", "fasta")
 aligner = Align.PairwiseAligner()
 score = aligner.score(seq1.seq, seq2.seq)
 print(score)
 alignments = aligner.align(seq1.seq, seq2.seq)
 len(alignments)
 alignment = alignments[0]
 print(alignment.score)
 print(alignment)  #doctest: +ELLIPSIS
 from Bio import Align
 from Bio import SeqIO
 from Bio.Align import substitution_matrices
 seq1 = SeqIO.read("alpha.faa", "fasta")
 seq2 = SeqIO.read("beta.faa", "fasta")
 aligner = Align.PairwiseAligner()
 aligner.open_gap_score = -10
 aligner.extend_gap_score = -0.5
 aligner.substitution_matrix = substitution_matrices.load("BLOSUM62")
 score = aligner.score(seq1.seq, seq2.seq)
 print(score)
 alignments = aligner.align(seq1.seq, seq2.seq)
 len(alignments)
 print(alignments[0].score)
 print(alignments[0])  #doctest: +ELLIPSIS
<BLANKLINE
 aligner.mode = 'local'
 aligner.open_gap_score = -10
 aligner.extend_gap_score = -1
 alignments = aligner.align("LSPADKTNVKAA", "PEEKSAV")
 print(len(alignments))
 alignment = alignments[0]
 print(alignment)
<BLANKLINE
 print(alignment.score)
 from Bio.Align import substitution_matrices
 m = substitution_matrices.load("SCHNEIDER")
 m.alphabet  #doctest: +ELLIPSIS
 from Bio import Align
 aligner = Align.PairwiseAligner()
 aligner.substitution_matrix = m
 aligner.gap_score = -1.0
 s1 = ('AAT', 'CTG', 'TTT', 'TTT')
 s2 = ('AAT', 'TTA', 'TTT')
 alignments = aligner.align(s1, s2)
 len(alignments)
 print(alignments[0])
<BLANKLINE
 print(alignments[1])
<BLANKLINE
 print(m['CTG', 'TTA'])
 print(m['TTT', 'TTA'])
 s1 = ('AAT', 'CTG', 'CTC', 'TTT')
 s2 = ('AAT', 'TTA', 'TTT')
 alignments = aligner.align(s1, s2)
 len(alignments)
 print(alignments[0])
<BLANKLINE
 print(m['CTC', 'TTA'])
 s1 = ('Asn', 'Leu', 'Leu', 'Phe')
 s2 = ('Asn', 'Leu', 'Phe')
 from Bio import Align
 aligner = Align.PairwiseAligner()
 aligner.alphabet = ['Ala', 'Arg', 'Asn', 'Asp', 'Cys',
 aligner.match = +6
 aligner.mismatch = -1
 alignments = aligner.align(s1, s2)
 print(len(alignments))
 print(alignments[0])
<BLANKLINE
 print(alignments[1])
<BLANKLINE
 print(alignments.score)
 import numpy
 from Bio import Align
 aligner = Align.PairwiseAligner()
 s1 = numpy.array([2, 10, 10, 13], numpy.int32)
 s2 = numpy.array([2, 10, 13], numpy.int32)
 aligner.match = +6
 aligner.mismatch = -1
 alignments = aligner.align(s1, s2)
 print(len(alignments))
 print(alignments[0])
<BLANKLINE
 print(alignments[1])
<BLANKLINE
 print(alignments.score)
 s2 = numpy.array([2, -5, 13], numpy.int32)
 aligner.gap_score = -3
 alignments = aligner.align(s1, s2)
 print(len(alignments))
 print(alignments[0])
<BLANKLINE
 print(alignments[1])
<BLANKLINE
 print(alignments.score)
 from Bio import Align
 import numpy
 aligner = Align.PairwiseAligner()
 m = numpy.eye(5)
 m[0, 1:] = m[1:, 0] = -2
 m[2,2] = 3
 print(m)
 aligner.substitution_matrix = m
 aligner.gap_score = -1
 s1 = numpy.array([0, 2, 3, 4], numpy.int32)
 s2 = numpy.array([0, 3, 2, 1], numpy.int32)
 alignments = aligner.align(s1, s2)
 print(len(alignments))
 print(alignments[0])
<BLANKLINE
 print(alignments[1])
<BLANKLINE
 print(alignments.score)
 from Bio.Align.substitution_matrices import Array
 counts = Array("ACGT")
 print(counts)
<BLANKLINE
 counts.alphabet
 counts['C'] = -3
 counts[2] = 7
 print(counts)
<BLANKLINE
 counts[1]
 counts['U']
 counts['X'] = 6
 counts[7]
 from Bio.Align.substitution_matrices import Array
 counts = Array("ACGT", dims=2)
 print(counts)
<BLANKLINE
 counts['A', 'C'] = 12.0
 counts[2, 1] = 5.0
 counts[3, 'T'] = -2
 print(counts)
<BLANKLINE
 counts['X', 1]
 counts['A', 5]
 counts = Array("ACGT", dims=2)
 counts['A', 'C'] = 12.0
 counts[2, 1] = 5.0
 counts[3, 'T'] = -2
 counts['G']
 counts[:, 'C']
 import numpy
 x = Array("ACGT")
 x['C'] = 5
 x
 a = numpy.array(x)  # create a plain numpy array
 a
 d = dict(x)  # create a plain dictionary
 d
 a = Array("ABCD", dims=2, data=numpy.arange(16).reshape(4,4))
 print(a)
<BLANKLINE
 b = a.select("CAD")
 print(b)
<BLANKLINE
 c = a.select("DEC")
 print(c)
<BLANKLINE
 from Bio.Align import PairwiseAligner
 aligner = PairwiseAligner()
 aligner.mode = 'local'
 aligner.match_score = 2
 aligner.mismatch_score = -3
 aligner.open_gap_score = -7
 aligner.extend_gap_score = -2
 from Bio import SeqIO
 sequence1 = SeqIO.read('ecoli.fa', 'fasta')
 sequence2 = SeqIO.read('bsubtilis.fa', 'fasta')
 alignments = aligner.align(sequence1.seq, sequence2.seq)
 len(alignments)
 alignment = alignments[0]
 from Bio.Align.substitution_matrices import Array
 frequency = Array("ACGT", dims=2)
 for (start1, end1), (start2, end2) in zip(*alignment.aligned):
 print(frequency)
<BLANKLINE
 import numpy
 probabilities = frequency / numpy.sum(frequency)
 probabilities = (probabilities + probabilities.transpose()) / 2.0
 print(format(probabilities, "%.4f"))
<BLANKLINE
 background = numpy.sum(probabilities, 0)
 print(format(background, "%.4f"))
<BLANKLINE
 expected = numpy.dot(background[:,None], background[None, :])
 print(format(expected, "%.4f"))
<BLANKLINE
 oddsratios = probabilities / expected
 scoring_matrix = numpy.log2(oddsratios)
 print(scoring_matrix)
<BLANKLINE
 aligner.substitution_matrix = scoring_matrix
 from Bio.Align.substitution_matrices import Array
 d = Array("ACGT")
 r = Array("ACGU")
 d + r
 from Bio.Align import substitution_matrices
 with open("hg38.chrom.sizes") as handle:
 print(table)  #doctest: +ELLIPSIS
<BLANKLINE
 with open("hg38.chrom.sizes") as handle:
 print(table)  #doctest: +ELLIPSIS
<BLANKLINE
#  Cluster Percentage: = 62
 from Bio.Align import substitution_matrices
 with open("BLOSUM62") as handle:
 print(matrix.alphabet)
 print(matrix['A','D'])
 matrix.header[0]
 from Bio.Align import PairwiseAligner
 aligner = PairwiseAligner()
 aligner.substitution_matrix = matrix
 text = format(matrix)
 print(text)  #doctest: +ELLIPSIS
#  Cluster Percentage: = 62
 from Bio.Align import substitution_matrices
 m = substitution_matrices.load("BLOSUM62")
 m.alphabet
 substitution_matrices.load()  #doctest: +ELLIPSIS
 m = substitution_matrices.load("SCHNEIDER")
 m.alphabet  #doctest: +ELLIPSIS
 from Bio.Blast import NCBIWWW
 help(NCBIWWW.qblast)
 from Bio.Blast import NCBIWWW
 result_handle = NCBIWWW.qblast("blastn", "nt", "8332116")
 from Bio.Blast import NCBIWWW
 fasta_string = open("m_cold.fasta").read()
 result_handle = NCBIWWW.qblast("blastn", "nt", fasta_string)
 from Bio.Blast import NCBIWWW
 from Bio import SeqIO
 record = SeqIO.read("m_cold.fasta", format="fasta")
 result_handle = NCBIWWW.qblast("blastn", "nt", record.seq)
 from Bio.Blast import NCBIWWW
 from Bio import SeqIO
 record = SeqIO.read("m_cold.fasta", format="fasta")
 result_handle = NCBIWWW.qblast("blastn", "nt", record.format("fasta"))
 with open("my_blast.xml", "w") as out_handle:
 result_handle.close()
 result_handle = open("my_blast.xml")
 from Bio.Blast.Applications import NcbiblastxCommandline
 help(NcbiblastxCommandline)
 blastx_cline = NcbiblastxCommandline(query="opuntia.fasta", db="nr", evalue=
 blastx_cline
 print(blastx_cline)
 stdout, stderr = blastx_cline()
 from Bio.Blast import NCBIWWW
 result_handle = NCBIWWW.qblast("blastn", "nt", "8332116")
 result_handle = open("my_blast.xml")
 from Bio.Blast import NCBIXML
 blast_record = NCBIXML.read(result_handle)
 from Bio.Blast import NCBIXML
 blast_records = NCBIXML.parse(result_handle)
 from Bio.Blast import NCBIXML
 blast_records = NCBIXML.parse(result_handle)
 blast_record = next(blast_records)
 blast_record = next(blast_records)
 blast_record = next(blast_records)
 blast_record = next(blast_records)
  File "<stdin", line 1, in <module
 for blast_record in blast_records:
 blast_records = list(blast_records)
 from Bio.Blast import NCBIXML
 blast_records = NCBIXML.parse(result_handle)
 blast_record = next(blast_records)
 from Bio.Blast import NCBIXML
 blast_record = NCBIXML.read(result_handle)
 E_VALUE_THRESH = 0.04
 for alignment in blast_record.alignments:
sequence: gb|AF283004.1|AF283004 Arabidopsis thaliana cold acclimation protein
mystery_seq
 from Bio import SearchIO
 blast_qresult = SearchIO.read("my_blast.xml", "blast-xml")
 print(blast_qresult)
 blat_qresult = SearchIO.read("my_blat.psl", "blat-psl")
 print(blat_qresult)
Program: blat (<unknown version)
         <unknown description
 Target: <unknown target
            0     17  chr19  <unknown description
       the program version so it defaults to ‘<unknown version’.
 print("%s %s" % (blast_qresult.program, blast_qresult.version))
 print("%s %s" % (blat_qresult.program, blat_qresult.version))
blat <unknown version
 blast_qresult.param_evalue_threshold    # blast-xml specific
 for hit in blast_qresult:
 len(blast_qresult)
 len(blat_qresult)
 blast_qresult[0]        # retrieves the top hit
 blast_qresult[-1]       # retrieves the last hit
 blast_slice = blast_qresult[:3]     # slices the first three hits
 print(blast_slice)
 blast_qresult["gi|262205317|ref|NR_030195.1|"]
 blast_qresult.hits
 blast_qresult.hit_keys
 "gi|262205317|ref|NR_030195.1|" in blast_qresult
 "gi|262205317|ref|NR_030194.1|" in blast_qresult
 blast_qresult.index("gi|301171437|ref|NR_035870.1|")
 for hit in blast_qresult[:5]:   # id and sequence length of the first five h
 sort_key = lambda hit: hit.seq_len
 sorted_qresult = blast_qresult.sort(key=sort_key, reverse=True, in_place=Fal
 for hit in sorted_qresult[:5]:
 filter_func = lambda hit: len(hit.hsps)  1     # the callback function
 len(blast_qresult)      # no. of hits before filtering
 filtered_qresult = blast_qresult.hit_filter(filter_func)
 len(filtered_qresult)   # no. of hits after filtering
 for hit in filtered_qresult[:5]:    # quick check for the hit lengths
 def map_func(hit):
 mapped_qresult = blast_qresult.hit_map(map_func)
 for hit in mapped_qresult[:5]:
 from Bio import SearchIO
 blast_qresult = SearchIO.read("my_blast.xml", "blast-xml")
 blast_hit = blast_qresult[3]    # fourth hit from the query result
 print(blast_hit)
 blat_qresult = SearchIO.read("my_blat.psl", "blat-psl")
 blat_hit = blat_qresult[0]      # the only hit
 print(blat_hit)
       <unknown description
       <unknown description
 for hsp in blast_hit:
 len(blast_hit)
 len(blat_hit)
 blat_hit[0]                 # retrieve single items
 sliced_hit = blat_hit[4:9]  # retrieve multiple items
 len(sliced_hit)
 print(sliced_hit)
       <unknown description
       <unknown description
 from Bio import SearchIO
 blast_qresult = SearchIO.read("my_blast.xml", "blast-xml")
 blast_hsp = blast_qresult[0][0]    # first hit, first hsp
 print(blast_hsp)
 blast_hsp.query_range
 blast_hsp.evalue
 blast_hsp.hit_start         # start coordinate of the hit sequence
 blast_hsp.query_span        # how many residues in the query sequence
 blast_hsp.aln_span          # how long the alignment is
 blast_hsp.gap_num       # number of gaps
 blast_hsp.ident_num     # number of identical residues
 blast_hsp.__dict__.keys()
 blast_hsp.query
 blast_hsp.hit
 print(blast_hsp.aln)
 blat_qresult = SearchIO.read("my_blat.psl", "blat-psl")
 blat_hsp = blat_qresult[0][0]       # first hit, first hsp
 print(blat_hsp)
      Query: mystery_seq <unknown description
        Hit: chr19 <unknown description
 blat_hsp.hit is None
 blat_hsp.query is None
 blat_hsp.aln is None
 blat_hsp.query_span     # length of query match
 blat_hsp.hit_span       # length of hit match
 blat_hsp.score          # PSL score
 blat_hsp.mismatch_num   # the mismatch column
 blat_hsp2 = blat_qresult[0][1]      # first hit, second hsp
 print(blat_hsp2)
      Query: mystery_seq <unknown description
        Hit: chr19 <unknown description
 blat_hsp2.hit_range         # hit start and end coordinates of the entire HS
 blat_hsp2.hit_range_all     # hit start and end coordinates of each fragment
 blat_hsp2.hit_span          # hit span of the entire HSP
 blat_hsp2.hit_span_all      # hit span of each fragment
 blat_hsp2.hit_inter_ranges  # start and end coordinates of intervening regio
 blat_hsp2.hit_inter_spans   # span of intervening regions in the hit sequenc
 blat_hsp2.is_fragmented     # BLAT HSP with 2 fragments
 blat_hsp.is_fragmented      # BLAT HSP from earlier, with one fragment
 from Bio import SearchIO
 blast_qresult = SearchIO.read("my_blast.xml", "blast-xml")
 blast_frag = blast_qresult[0][0][0]    # first hit, first hsp, first fragmen
 print(blast_frag)
 blat_qresult = SearchIO.read("my_blat.psl", "blat-psl")
 blat_frag = blat_qresult[0][0][0]    # first hit, first hsp, first fragment
 print(blat_frag)
      Query: mystery_seq <unknown description
        Hit: chr19 <unknown description
 blast_frag.query_start      # query start coordinate
 blast_frag.hit_strand       # hit sequence strand
 blast_frag.hit              # hit sequence, as a SeqRecord object
 from Bio import SearchIO
 qresult = SearchIO.read("tab_2226_tblastn_003.txt", "blast-tab")
 qresult
 qresult2 = SearchIO.read("tab_2226_tblastn_007.txt", "blast-tab", comments=T
 qresult2
 from Bio import SearchIO
 qresults = SearchIO.parse("tab_2226_tblastn_001.txt", "blast-tab")
 for qresult in qresults:
 qresults2 = SearchIO.parse("tab_2226_tblastn_005.txt", "blast-tab", comments
 for qresult in qresults2:
 from Bio import SearchIO
 idx = SearchIO.index("tab_2226_tblastn_001.txt", "blast-tab")
 sorted(idx.keys())
 idx["gi|16080617|ref|NP_391444.1|"]
 idx.close()
 idx = SearchIO.index("tab_2226_tblastn_005.txt", "blast-tab", comments=True)
 sorted(idx.keys())
 idx["gi|16080617|ref|NP_391444.1|"]
 idx.close()
 key_function = lambda id: id.upper()    # capitalizes the keys
 idx = SearchIO.index("tab_2226_tblastn_001.txt", "blast-tab", key_function=k
 sorted(idx.keys())
 idx["GI|16080617|REF|NP_391444.1|"]
 idx.close()
 from Bio import SearchIO
 qresults = SearchIO.parse("mirna.xml", "blast-xml")     # read XML file
 SearchIO.write(qresults, "results.tab", "blast-tab")    # write to tabular f
 from Bio import SearchIO
 SearchIO.convert("mirna.xml", "blast-xml", "results.tab", "blast-tab")
 from Bio import Entrez
 Entrez.api_key = "MyAPIkey"
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"
 from Bio import Entrez
 Entrez.tool = "MyLocalScript"
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.einfo()
 result = handle.read()
 handle.close()
 print(result)
<?xml version="1.0"?
 "https://www.ncbi.nlm.nih.gov/entrez/query/DTD/eInfo_020511.dtd"
<eInfoResult
<DbList
        <DbNamepubmed</DbName
        <DbNameprotein</DbName
        <DbNamenucleotide</DbName
        <DbNamenuccore</DbName
        <DbNamenucgss</DbName
        <DbNamenucest</DbName
        <DbNamestructure</DbName
        <DbNamegenome</DbName
        <DbNamebooks</DbName
        <DbNamecancerchromosomes</DbName
        <DbNamecdd</DbName
        <DbNamegap</DbName
        <DbNamedomains</DbName
        <DbNamegene</DbName
        <DbNamegenomeprj</DbName
        <DbNamegensat</DbName
        <DbNamegeo</DbName
        <DbNamegds</DbName
        <DbNamehomologene</DbName
        <DbNamejournals</DbName
        <DbNamemesh</DbName
        <DbNamencbisearch</DbName
        <DbNamenlmcatalog</DbName
        <DbNameomia</DbName
        <DbNameomim</DbName
        <DbNamepmc</DbName
        <DbNamepopset</DbName
        <DbNameprobe</DbName
        <DbNameproteinclusters</DbName
        <DbNamepcassay</DbName
        <DbNamepccompound</DbName
        <DbNamepcsubstance</DbName
        <DbNamesnp</DbName
        <DbNametaxonomy</DbName
        <DbNametoolkit</DbName
        <DbNameunigene</DbName
        <DbNameunists</DbName
</DbList
</eInfoResult
 from Bio import Entrez
 handle = Entrez.einfo()
 record = Entrez.read(handle)
 record.keys()
 record["DbList"]
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.einfo(db="pubmed")
 record = Entrez.read(handle)
 record["DbInfo"]["Description"]
 record["DbInfo"]["Count"]
 record["DbInfo"]["LastUpdate"]
 for field in record["DbInfo"]["FieldList"]:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"     # Always tell NCBI who you are
 handle = Entrez.esearch(db="pubmed", term="biopython[title]", retmax="40" )
 record = Entrez.read(handle)
 "19304878" in record["IdList"]
 print(record["IdList"])
 handle = Entrez.esearch(db="nucleotide", term="Cypripedioideae[Orgn] AND mat
 record = Entrez.read(handle)
 record["Count"]
 record["IdList"]
 handle = Entrez.esearch(db="nlmcatalog", term="computational[Journal]", retm
 record = Entrez.read(handle)
 print("{} computational journals found".format(record["Count"]))
 print("The first 20 are\n{}".format(record["IdList"]))
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"     # Always tell NCBI who you are
 id_list = ["19304878", "18606172", "16403221", "16377612", "14871861", "1463
 print(Entrez.epost("pubmed", id=",".join(id_list)).read())
<?xml version="1.0"?
 "https://www.ncbi.nlm.nih.gov/entrez/query/DTD/ePost_020511.dtd"
<ePostResult
 <QueryKey1</QueryKey
 <WebEnvNCID_01_206841095_130.14.22.101_9001_1242061629</WebEnv
</ePostResult
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"     # Always tell NCBI who you are
 id_list = ["19304878", "18606172", "16403221", "16377612", "14871861", "1463
 search_results = Entrez.read(Entrez.epost("pubmed", id=",".join(id_list)))
 webenv = search_results["WebEnv"]
 query_key = search_results["QueryKey"]
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.esummary(db="nlmcatalog", id="101660833")
 record = Entrez.read(handle)
 info = record[0]["TitleMainList"][0]
 print("Journal info\nid: {}\nTitle: {}".format(record[0]["Id"], info["Title"
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.efetch(db="nucleotide", id="EU490707", rettype="gb", retmode
 print(handle.read())
     gene            <1..1302
     CDS             <1..1302
<BLANKLINE
<BLANKLINE
 from Bio import SeqIO
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.efetch(db="nucleotide", id="EU490707", rettype="gb", retmode
 record = SeqIO.read(handle, "genbank")
 handle.close()
 print(record.id)
 print(record.name)
 print(record.description)
 print(len(record.features))
 record.seq
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.efetch(db="nucleotide", id="EU490707", retmode="xml")
 record = Entrez.read(handle)
 handle.close()
 record[0]["GBSeq_definition"]
 record[0]["GBSeq_source"]
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 pmid = "19304878"
 record = Entrez.read(Entrez.elink(dbfrom="pubmed", id=pmid))
 record[0]["DbFrom"]
 record[0]["IdList"]
 len(record[0]["LinkSetDb"])
 for linksetdb in record[0]["LinkSetDb"]:
 record[0]["LinkSetDb"][0]["Link"][0]
 record[0]["LinkSetDb"][0]["Link"][1]
 for link in record[0]["LinkSetDb"][0]["Link"]:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.egquery(term="biopython")
 record = Entrez.read(handle)
 for row in record["eGQueryResult"]:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.espell(term="biopythooon")
 record = Entrez.read(handle)
 record["Query"]
 record["CorrectedQuery"]
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = open("Homo_sapiens.xml", "b")
 records = Entrez.parse(handle)
 for record in records:
<iP</i &lt; 0.05
'<iP</i < 0.05'
 record = Entrez.read(handle, escape=True)
'<iP</i &lt; 0.05'
 from Bio import Entrez
 handle = open("NC_005816.fna", "rb") # a Fasta file
 record = Entrez.read(handle)
<?xml version="1.0"?
/www.ncbi.nlm.nih.gov/entrez/query/DTD/eInfo_020511.dtd"
<eInfoResult
<DbList
        <DbNamepubmed</DbName
        <DbNameprotein</DbName
        <DbNamenucleotide</DbName
        <DbNamenuccore</DbName
        <DbNamenucgss</DbName
        <DbNamenucest</DbName
        <DbNamestructure</DbName
        <DbNamegenome</DbName
        <DbNamebooks</DbName
        <DbNamecancerchromosomes</DbName
        <DbNamecdd</DbName
 Entrez.read(handle)
<?xml version="1.0"?
/www.ncbi.nlm.nih.gov/entrez/query/DTD/eInfo_020511.dtd"
<eInfoResult
        <DbInfo
        <DbNamepubmed</DbName
        <MenuNamePubMed</MenuName
        <DescriptionPubMed bibliographic record</Description
        <Count20161961</Count
        <LastUpdate2010/09/10 04:52</LastUpdate
        <FieldList
                <Field
                </Field
        </FieldList
        <DocsumList
                <Docsum
                        <DsNamePubDate</DsName
                        <DsType4</DsType
                        <DsTypeNamestring</DsTypeName
                </Docsum
                <Docsum
                        <DsNameEPubDate</DsName
        </DbInfo
</eInfoResult
   In this file, for some reason the tag <DocsumList (and several others)
 from Bio import Entrez
 handle = open("einfo3.xml", "rb")
 record = Entrez.read(handle)
 from Bio import Entrez
 handle = open("einfo3.xml", "rb")
 record = Entrez.read(handle, validate=False)
 handle.close()
 from Bio import Medline
 with open("pubmed_result1.txt") as handle:
 record["PMID"]
 record["AB"]
 help(record)
 from Bio import Medline
 with open("pubmed_result2.txt") as handle:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.esearch(db="pubmed", term="biopython")
 record = Entrez.read(handle)
 record["IdList"]
 idlist = record["IdList"]
 handle = Entrez.efetch(db="pubmed", id=idlist, rettype="medline", retmode="t
 from Bio import Medline
 records = Medline.parse(handle)
 for record in records:
 handle = Entrez.efetch(db="pubmed", id=idlist, rettype="medline", retmode="x
 records = Entrez.read(handle)
 for record in records["PubmedArticle"]:
 from Bio import Geo
 handle = open("GSE16.txt")
 records = Geo.parse(handle)
 for record in records:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.esearch(db="gds", term="GSE16")
 record = Entrez.read(handle)
 handle.close()
 record["Count"]
 record["IdList"]
 from Bio import UniGene
 input = open("myunigenefile.data")
 record = UniGene.read(input)
 record.ID
 record.title
 record.sts[0].acc
 record.sts[0].unists
 from Bio import UniGene
 input = open("unigenerecords.data")
 records = UniGene.parse(input)
 for record in records:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.egquery(term="orchid")
 record = Entrez.read(handle)
 for row in record["eGQueryResult"]:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.esearch(db="pubmed", term="orchid", retmax=463)
 record = Entrez.read(handle)
 handle.close()
 idlist = record["IdList"]
 print(idlist)
 from Bio import Medline
 handle = Entrez.efetch(db="pubmed", id=idlist, rettype="medline",
 records = Medline.parse(handle)
 records = list(records)
 for record in records:
 search_author = "Waits T"
 for record in records:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.egquery(term="Cypripedioideae")
 record = Entrez.read(handle)
 for row in record["eGQueryResult"]:
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.esearch(db="nucleotide", term="Cypripedioideae", retmax=814,
 record = Entrez.read(handle)
 handle.close()
 print(record.keys())
 print(record["Count"])
 len(record["IdList"])
 record["IdList"][:5]
 idlist = ",".join(record["IdList"][:5])
 print(idlist)
 handle = Entrez.efetch(db="nucleotide", id=idlist, retmode="xml")
 records = Entrez.read(handle)
 len(records)
 print(records[0].keys())
 print(records[0]["GBSeq_primary-accession"])
 print(records[0]["GBSeq_other-seqids"])
 print(records[0]["GBSeq_definition"])
 print(records[0]["GBSeq_organism"])
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.egquery(term="Opuntia AND rpl16")
 record = Entrez.read(handle)
 for row in record["eGQueryResult"]:
 handle = Entrez.esearch(db="nuccore", term="Opuntia AND rpl16")
 record = Entrez.read(handle)
 gi_list = record["IdList"]
 gi_list
 gi_str = ",".join(gi_list)
 handle = Entrez.efetch(db="nuccore", id=gi_str, rettype="gb", retmode="text"
 text = handle.read()
 print(text)
 from Bio import SeqIO
 handle = Entrez.efetch(db="nuccore", id=gi_str, rettype="gb", retmode="text"
 records = SeqIO.parse(handle, "gb")
 for record in records:
 ...    print("%s, length %i, with %i features"
 ...           % (record.name, len(record), len(record.features)))
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 handle = Entrez.esearch(db="Taxonomy", term="Cypripedioideae")
 record = Entrez.read(handle)
 record["IdList"]
 record["IdList"][0]
 handle = Entrez.efetch(db="Taxonomy", id="158330", retmode="xml")
 records = Entrez.read(handle)
 records[0].keys()
 records[0]["Lineage"]
 from Bio import Entrez
 Entrez.email = "history.user@example.com"  # Always tell NCBI who you are
 search_handle = Entrez.esearch(db="nucleotide",term="Opuntia[orgn] and rpl16
 search_results = Entrez.read(search_handle)
 search_handle.close()
 acc_list = search_results["IdList"]
 count = int(search_results["Count"])
 count == len(acc_list)
 webenv = search_results["WebEnv"]
 query_key = search_results["QueryKey"]
 from Bio import Entrez
 Entrez.email = "A.N.Other@example.com"  # Always tell NCBI who you are
 pmid = "14630660"
 results = Entrez.read(Entrez.elink(dbfrom="pubmed", db="pmc",
 pmc_ids = [link["Id"] for link in results[0]["LinkSetDb"][0]["Link"]]
 pmc_ids
 results2 = Entrez.read(Entrez.elink(dbfrom="pmc", db="pubmed", LinkName="pmc
 pubmed_ids = [link["Id"] for link in results2[0]["LinkSetDb"][0]["Link"]]
 pubmed_ids
 handle = open("myswissprotfile.dat")
 import gzip
 handle = gzip.open("myswissprotfile.dat.gz", "rt")
 from urllib.request import urlopen
 url = "https://raw.githubusercontent.com/biopython/biopython/master/Tests/Sw
 handle = urlopen(url)
 from Bio import ExPASy
 handle = ExPASy.get_sprot_raw(myaccessionnumber)
 from Bio import SwissProt
 record = SwissProt.read(handle)
 print(record.description)
 for ref in record.references:
 import gzip
 handle = gzip.open("uniprot_sprot.dat.gz", "rt")
 handle = open("uniprot_sprot.dat")
 from Bio import SwissProt
 handle = open("uniprot_sprot.dat")
 descriptions = [record.description for record in SwissProt.parse(handle)]
 len(descriptions)
 descriptions[:5]
 from Bio import SwissProt
 descriptions = []
 handle = open("uniprot_sprot.dat")
 for record in SwissProt.parse(handle):
 len(descriptions)
 dir(record)
 from Bio.SwissProt import KeyWList
 handle = open("keywlist.txt")
 records = KeyWList.parse(handle)
 for record in records:
 from Bio.ExPASy import Prosite
 handle = open("myprositefile.dat")
 records = Prosite.parse(handle)
 from Bio.ExPASy import Prosite
 handle = open("prosite.dat")
 records = Prosite.parse(handle)
 record = next(records)
 record.accession
 record.name
 record.pdoc
 record = next(records)
 record.accession
 record.name
 record.pdoc
 record = next(records)
 record.accession
 record.name
 record.pdoc
 from Bio.ExPASy import Prosite
 handle = open("prosite.dat")
 records = Prosite.parse(handle)
 n = 0
 for record in records: n+=1
 n
 from Bio.ExPASy import Prosite
 handle = open("mysingleprositerecord.dat")
 record = Prosite.read(handle)
 from Bio.ExPASy import Prodoc
 handle = open("prosite.doc")
 records = Prodoc.parse(handle)
 accessions = [record.accession for record in records]
 from Bio.ExPASy import Enzyme
 with open("lipoprotein.txt") as handle:
 record["ID"]
 record["DE"]
 record["AN"]
 record["CA"]
 record["PR"]
 record["CC"]
 record["DR"]
 from Bio.ExPASy import Enzyme
 handle = open("enzyme.dat")
 records = Enzyme.parse(handle)
 ecnumbers = [record["ID"] for record in records]
 from Bio import ExPASy
 from Bio import SwissProt
 accessions = ["O23729", "O23730", "O23731"]
 records = []
 for accession in accessions:
 for accession in accessions:
 from Bio import ExPASy
 handle = ExPASy.get_prosite_raw("PS00001")
 text = handle.read()
 print(text)
 from Bio import ExPASy
 from Bio import Prosite
 handle = ExPASy.get_prosite_raw("PS00001")
 record = Prosite.read(handle)
 from Bio import ExPASy
 from Bio.ExPASy import Prodoc
 handle = ExPASy.get_prosite_raw("PDOC00001")
 record = Prodoc.read(handle)
 from Bio import ExPASy
 handle = ExPASy.get_prosite_entry("PS00001")
 html = handle.read()
 with open("myprositerecord.html", "w") as out_handle:
 from Bio import ExPASy
 handle = ExPASy.get_prodoc_entry("PDOC00001")
 html = handle.read()
 with open("myprodocrecord.html", "w") as out_handle:
 sequence = "MEHKEVVLLLLLFLKSGQGEPLDDYVNTQGASLFSVTKKQLGAGSIEECAAKCEEDEEFT
 from Bio.ExPASy import ScanProsite
 handle = ScanProsite.scan(seq=sequence)
 result = ScanProsite.read(handle)
 type(result)
<class 'Bio.ExPASy.ScanProsite.Record'
 result.n_seq
 result.n_match
 len(result)
 result[0]
 result[1]
 result[2]
 result[3]
 result[4]
 result[5]
 handle = ScanProsite.scan(seq=sequence, lowscore=1)
 result = ScanProsite.read(handle)
 result.n_match
 from Bio.PDB.MMCIFParser import MMCIFParser
 parser = MMCIFParser()
 structure = parser.get_structure("1fat", "1fat.cif")
 from Bio.PDB.MMCIF2Dict import MMCIF2Dict
 mmcif_dict = MMCIF2Dict("1FAT.cif")
 sc = mmcif_dict["_exptl_crystal.density_percent_sol"]
 y_list = mmcif_dict["_atom_site.Cartn_y"]
 from Bio.PDB.mmtf import MMTFParser
 structure = MMTFParser.get_structure("PDB/4CUP.mmtf")
 structure = MMTFParser.get_structure_from_url("4CUP")
 from mmtf import fetch
 decoded_data = fetch("4CUP")
 print(decoded_data.x_coord_list)
 from Bio.PDB.PDBParser import PDBParser
 parser = PDBParser(PERMISSIVE=1)
 structure_id = "1fat"
 filename = "pdb1fat.ent"
 structure = parser.get_structure(structure_id, filename)
 resolution = structure.header["resolution"]
 keywords = structure.header["keywords"]
 from Bio.PDB import parse_pdb_header
 with open(filename, "r") as handle:
 from Bio.PDB.PDBParser import PDBParser
 pqr_parser = PDBParser(PERMISSIVE=1, is_pqr=True)
 structure_id = "1fat"
 filename = "pdb1fat.ent"
 structure = parser.get_structure(structure_id, filename, is_pqr=True)
 io = MMCIFIO()
 io.set_structure(s)
 io.save("out.cif")
 io = MMCIFIO()
 io.set_dict(d)
 io.save("out.cif")
 io = PDBIO()
 io.set_structure(s)
 io.save("out.pdb")
 class GlySelect(Select):
 io = PDBIO()
 io.set_structure(s)
 io.save("gly_only.pdb", GlySelect())
 io = PDBIO(is_pqr=True)
 io.set_structure(s)
 io.save("out.pdb")
 from Bio.PDB.mmtf import MMTFIO
 io = MMTFIO()
 io.set_structure(s)
 io.save("out.mmtf")
 child_entity = parent_entity[child_id]
 child_list = parent_entity.get_list()
 parent_entity = child_entity.get_parent()
 full_id = residue.get_full_id()
 print(full_id)
 entity.get_id()
 entity.has_id(entity_id)
 nr_children = len(entity)
 first_model = structure[0]
 chain_A = model["A"]
 residue=chain[(" ", 100, " ")]
 residue=chain[100]
 res10 = chain[(" ", 10, " ")]
 res10 = chain[10]
 residue.get_resname()    # returns the residue name, e.g. "ASN"
 residue.is_disordered()  # returns 1 if the residue has disordered atoms
 residue.get_segid()      # returns the SEGID, e.g. "CHN1"
 residue.has_id(name)     # test if a residue has a certain atom
 a.get_name()       # atom name (spaces stripped, e.g. "CA")
 a.get_id()         # id (equals atom name)
 a.get_coord()      # atomic coordinates
 a.get_vector()     # atomic coordinates as Vector object
 a.get_bfactor()    # isotropic B factor
 a.get_occupancy()  # occupancy
 a.get_altloc()     # alternative location specifier
 a.get_sigatm()     # standard deviation of atomic parameters
 a.get_siguij()     # standard deviation of anisotropic B factor
 a.get_anisou()     # anisotropic B factor
 a.get_fullname()   # atom name (with spaces, e.g. ".CA.")
 n = residue["N"].get_vector()
 c = residue["C"].get_vector()
 ca = residue["CA"].get_vector()
 n = n - ca
 c = c - ca
 rot = rotaxis(-pi * 120.0/180.0, c)
 cb_at_origin = n.left_multiply(rot)
 cb = cb_at_origin+ca
 model = structure[0]
 chain = model["A"]
 residue = chain[100]
 atom = residue["CA"]
 atom = structure[0]["A"][100]["CA"]
 atom.disordered_select("A") # select altloc A atom
 print(atom.get_altloc())
 atom.disordered_select("B") # select altloc B atom
 print(atom.get_altloc())
 residue = chain[10]
 residue.disordered_select("CYS")
 from Bio.PDB.PDBParser import PDBParser
 parser = PDBParser()
 structure = parser.get_structure("test", "1fat.pdb")
 model = structure[0]
 chain = model["A"]
 residue = chain[1]
 atom = residue["CA"]
 p = PDBParser()
 structure = p.get_structure("X", "pdb1fat.ent")
 for model in structure:
 atoms = structure.get_atoms()
 for atom in atoms:
 atoms = chain.get_atoms()
 for atom in atoms:
 residues = model.get_residues()
 for residue in residues:
 res_list = Selection.unfold_entities(structure, "R")
 atom_list = Selection.unfold_entities(chain, "A")
 residue_list = Selection.unfold_entities(atom_list, "R")
 chain_list = Selection.unfold_entities(atom_list, "C")
 residue_id = ("H_GLC", 10, " ")
 residue = chain[residue_id]
 for residue in chain.get_list():
 for model in structure.get_list():
...                 if ca.get_bfactor()  50.0:
 for model in structure.get_list():
 for model in structure.get_list():
 model_nr = 1
 polypeptide_list = build_peptides(structure, model_nr)
 for polypeptide in polypeptide_list:
 ppb=PPBuilder()
 for pp in ppb.build_peptides(structure):
 ppb=CaPPBuilder()
 for pp in ppb.build_peptides(structure):
 seq = polypeptide.get_sequence()
 seq
 ca1 = residue1["CA"]
 ca2 = residue2["CA"]
 distance = ca1-ca2
 vector1 = atom1.get_vector()
 vector2 = atom2.get_vector()
 vector3 = atom3.get_vector()
 angle = calc_angle(vector1, vector2, vector3)
 vector1 = atom1.get_vector()
 vector2 = atom2.get_vector()
 vector3 = atom3.get_vector()
 vector4 = atom4.get_vector()
 angle = calc_dihedral(vector1, vector2, vector3, vector4)
 model.atom_to_internal_coordinates()
 for r in model.get_residues():
 sup = Superimposer()
 sup.set_atoms(fixed, moving)
 print(sup.rotran)
 print(sup.rms)
 sup.apply(moving)
 model = structure[0]
 hse = HSExposure()
 exp_ca = hse.calc_hs_exposure(model, option="CA3")
 exp_cb=hse.calc_hs_exposure(model, option="CB")
 exp_fs = hse.calc_fs_exposure(model)
 print(exp_ca[some_residue])
 model = structure[0]
 rd = ResidueDepth(model, pdb_file)
 residue_depth, ca_depth=rd[some_residue]
 parser = PDBParser(PERMISSIVE=1)
 parser = PDBParser() # The same (default)
 strict_parser = PDBParser(PERMISSIVE=0)
 pdbl = PDBList()
 pdbl.retrieve_pdb_file("1FAT")
 pl = PDBList(pdb="/data/pdb")
 pl.update_pdb()
 from Bio import Phylo
 tree = Phylo.read("simple.dnd", "newick")
 print(tree)
 from Bio import Phylo
 tree = Phylo.read("simple.dnd", "newick")
 Phylo.draw_ascii(tree)
<BLANKLINE
 tree.rooted = True
 Phylo.draw(tree)
 tree = tree.as_phyloxml()
 from Bio.Phylo.PhyloXML import Phylogeny
 tree = Phylogeny.from_tree(tree)
 tree.root.color = (128, 128, 128)
 tree.root.color = "#808080"
 tree.root.color = "gray"
 mrca = tree.common_ancestor({"name": "E"}, {"name": "F"})
 mrca.color = "salmon"
 tree.clade[0, 1].color = "blue"
 Phylo.draw(tree)
 import sys
 Phylo.write(tree, sys.stdout, "phyloxml")
<phy:phyloxml xmlns:phy="http://www.phyloxml.org"
  <phy:phylogeny rooted="true"
    <phy:clade
      <phy:branch_length1.0</phy:branch_length
      <phy:color
        <phy:red128</phy:red
        <phy:green128</phy:green
        <phy:blue128</phy:blue
      </phy:color
      <phy:clade
        <phy:branch_length1.0</phy:branch_length
        <phy:clade
          <phy:branch_length1.0</phy:branch_length
          <phy:clade
            <phy:nameA</phy:name
 from Bio import Phylo
 tree = Phylo.read("Tests/Nexus/int_node_labels.nwk", "newick")
 print(tree)
 trees = Phylo.parse("../../Tests/PhyloXML/phyloxml_examples.xml", "phyloxml"
 for tree in trees:
 trees = list(Phylo.parse("../../Tests/PhyloXML/phyloxml_examples.xml", "phyl
 tree1 = trees[0]
 others = trees[1:]
 Phylo.write(tree1, "tree1.nwk", "newick")
 Phylo.write(others, "other_trees.nwk", "newick")
 Phylo.convert("tree1.nwk", "newick", "tree1.xml", "nexml")
 Phylo.convert("other_trees.xml", "phyloxml", "other_trees.nex", "nexus")
 from Bio import Phylo
 from io import StringIO
 handle = StringIO("(((A,B),(C,D)),(E,F,G));")
 tree = Phylo.read(handle, "newick")
 from Bio import Phylo
 tree = Phylo.read("PhyloXML/example.xml", "phyloxml")
 print(tree)
 tree = Phylo.read("example.xml", "phyloxml")
 Phylo.draw_ascii(tree)
 tree = Phylo.read("example.xml", "phyloxml")
 Phylo.draw(tree, branch_labels=lambda c: c.branch_length)
 from Bio import Phylo
 from Bio.Phylo.Applications import PhymlCommandline
 cmd = PhymlCommandline(input="Tests/Phylip/random.phy")
 out_log, err_log = cmd()
 tree = Phylo.read("Tests/Phylip/random.phy_phyml_tree.txt", "newick")
 Phylo.draw_ascii(tree)
 from Bio.Phylo.PAML import codeml
 cml = codeml.Codeml()
 cml.alignment = "Tests/PAML/alignment.phylip"
 cml.tree = "Tests/PAML/species.tree"
 cml.out_file = "results.out"
 cml.working_dir = "./scratch"
 cml.set_options(seqtype=1,
 results = cml.run()
 ns_sites = results.get("NSsites")
 m0 = ns_sites.get(0)
 m0_params = m0.get("parameters")
 print(m0_params.get("omega"))
 results = codeml.read("Tests/PAML/Results/codeml/codeml_NSsites_all.out")
 print(results.get("lnL max"))
 from Bio import motifs
 from Bio.Seq import Seq
 instances = [Seq("TACAA"),
 m = motifs.create(instances)
 print(m)
<BLANKLINE
 len(m)
 print(m.counts)
<BLANKLINE
 m.counts["A"]
 m.counts["T", 0]
 m.counts["T", 2]
 m.counts["T", 3]
 m.counts[:, 3]
 m.alphabet
 m.counts["A",:]
 m.counts[0,:]
 m.consensus
 m.anticonsensus
 m.degenerate_consensus
 r = m.reverse_complement()
 r.consensus
 r.degenerate_consensus
 print(r)
<BLANKLINE
 m.weblogo("mymotif.png")
MA0004 ARNT 1
MA0004 ARNT 2
MA0004 ARNT 3
MA0004 ARNT 18
MA0004 ARNT 19
MA0004 ARNT 20
 from Bio import motifs
 with open("Arnt.sites") as handle:
 print(arnt.instances[:3])
 for instance in arnt.instances:
 print(arnt.counts)
<BLANKLINE
 with open("SRF.pfm") as handle:
 print(srf.counts)
<BLANKLINE
 print(srf.instances)
 print(arnt.counts.consensus)
 print(srf.counts.consensus)
   header line begins with a  character (similar to the Fasta file
MA0004.1 Arnt
MA0002.1 RUNX1
MA0052.1 MEF2A
 fh = open("jaspar_motifs.txt")
 for m in motifs.parse(fh, "jaspar"))
 from Bio.motifs.jaspar.db import JASPAR5

 JASPAR_DB_HOST = <hostname
 JASPAR_DB_NAME = <db_name
 JASPAR_DB_USER = <user
 JASPAR_DB_PASS = <passord

 jdb = JASPAR5(
 arnt = jdb.fetch_motif_by_id("MA0004")
 print(arnt)
 motifs = jdb.fetch_motifs_by_name("Arnt")
 print(motifs[0])
 motifs = jdb.fetch_motifs(
 for motif in motifs:
 motif.pseudocounts = motifs.jaspar.calculate_pseudocounts(motif)
 abs_score =  (pssm.max - pssm.min) * rel_score + pssm.min
 rel_score = (abs_score - pssm.min) / (pssm.max - pssm.min)
 test_seq=Seq("TAAGCGTGCACGCGCAACACGTGCATTA")
 arnt.pseudocounts = motifs.jaspar.calculate_pseudocounts(arnt)
 pssm = arnt.pssm
 max_score = pssm.max
 min_score = pssm.min
 abs_score_threshold = (max_score - min_score) * 0.8 + min_score
 for position, score in pssm.search(test_seq,
 with open("meme.INO_up800.classic.oops.xml") as handle:
 record.version
 record.datafile
 record.command
 record.alphabet
 record.sequences
 len(record)
 motif = record[0]
 print(motif.consensus)
 print(motif.degenerate_consensus)
 motif.num_occurrences
 motif.length
 evalue = motif.evalue
 print("%3.1g" % evalue)
 motif.name
 motif.id
 motif = record["GSKGCATGTGAAA"]
 len(motif.instances)
 motif.instances[0]
 motif.instances[0].motif_name
 motif.instances[0].sequence_name
 motif.instances[0].sequence_id
 motif.instances[0].start
 motif.instances[0].strand
 motif.instances[0].length
 pvalue = motif.instances[0].pvalue
 print("%5.3g" % pvalue)
 with open("transfac.dat") as handle:
 record = motifs.parse(handle, "TRANSFAC", strict=False)
 record.version
 motif = record[0]
 motif.degenerate_consensus # Using the Bio.motifs.Motif property
 motif["ID"] # Using motif as a dictionary
 print(record)
<BLANKLINE
 text = str(record)
 with open("mytransfacfile.dat", "w") as out_handle:
 print(format(arnt, "pfm"))
 print(format(arnt, "jaspar"))
MA0004.1  Arnt
 print(format(m, "transfac"))
<BLANKLINE
 two_motifs = [arnt, srf]
 print(motifs.write(two_motifs, "transfac"))
<BLANKLINE
 two_motifs = [arnt, mef2a]
 print(motifs.write(two_motifs, "jaspar"))
MA0004.1  Arnt
MA0052.1  MEF2A
 pwm = m.counts.normalize(pseudocounts=0.5)
 print(pwm)
<BLANKLINE
 pwm = m.counts.normalize(pseudocounts={"A":0.6, "C": 0.4, "G": 0.4, "T": 0.6
 print(pwm)
<BLANKLINE
 pwm.consensus
 pwm.anticonsensus
 pwm.degenerate_consensus
 m.degenerate_consensus
 rpwm = pwm.reverse_complement()
 print(rpwm)
<BLANKLINE
 pssm = pwm.log_odds()
 print(pssm)
<BLANKLINE
 background = {"A":0.3,"C":0.2,"G":0.2,"T":0.3}
 pssm = pwm.log_odds(background)
 print(pssm)
<BLANKLINE
 print("%4.2f" % pssm.max)
 print("%4.2f" % pssm.min)
 mean = pssm.mean(background)
 std = pssm.std(background)
 print("mean = %0.2f, standard deviation = %0.2f" % (mean, std))
 test_seq=Seq("TACACTGCATTACAACCCAAGCATTA")
 len(test_seq)
 for pos, seq in m.instances.search(test_seq):
 for pos, seq in r.instances.search(test_seq):
 for position, score in pssm.search(test_seq, threshold=3.0):
 pssm.calculate(test_seq)
 rpssm = pssm.reverse_complement()
 rpssm.calculate(test_seq)
 distribution = pssm.distribution(background=background, precision=10**4)
 threshold = distribution.threshold_fpr(0.01)
 print("%5.3f" % threshold)
 threshold = distribution.threshold_fnr(0.1)
 print("%5.3f" % threshold)
 threshold = distribution.threshold_balanced(1000)
 print("%5.3f" % threshold)
 threshold = distribution.threshold_patser()
 print("%5.3f" % threshold)
 threshold = distribution.threshold_fpr(0.01)
 print("%5.3f" % threshold)
 for position, score in pssm.search(test_seq, threshold=threshold):
 from Bio import motifs
 with open("Arnt.sites") as handle:
 print(motif.counts)
<BLANKLINE
 print(motif.pwm)
<BLANKLINE
 print(motif.pssm)
<BLANKLINE
 for letter in "ACGT":
 motif.pseudocounts = 3.0
 for letter in "ACGT":
 print(motif.pwm)
<BLANKLINE
 print(motif.pssm)
<BLANKLINE
 for letter in "ACGT":
 motif.background = {"A": 0.2, "C": 0.3, "G": 0.3, "T": 0.2}
 print(motif.pssm)
<BLANKLINE
 motif.background = None
 for letter in "ACGT":
 motif.background = 0.8
 for letter in "ACGT":
 print("%f" % motif.pssm.mean(motif.background))
 print("%f" % motif.pssm.std(motif.background))
 distribution = motif.pssm.distribution(background=motif.background)
 threshold = distribution.threshold_fpr(0.01)
 print("%f" % threshold)
 pssm = motif.pssm
 with open("REB1.pfm") as handle:
 m_reb1.consensus
 print(m_reb1.counts)
<BLANKLINE
 m_reb1.pseudocounts = {"A":0.6, "C": 0.4, "G": 0.4, "T": 0.6}
 m_reb1.background = {"A":0.3,"C":0.2,"G":0.2,"T":0.3}
 pssm_reb1 = m_reb1.pssm
 print(pssm_reb1)
<BLANKLINE
 distance, offset = pssm.dist_pearson(pssm_reb1)
 print("distance = %5.3g" % distance)
 print(offset)
 from Bio import motifs
 with open("meme.psp_test.classic.zoops.xml") as handle:
 motifsM
[<Bio.motifs.meme.Motif object at 0xc356b0]
 motifsM[0].consensus
 motifsM[0].instances[0].sequence_name
 motifsM[0].instances[0].sequence_id
 motifsM[0].instances[0].start
 motifsM[0].instances[0].strand
 motifsM[0].instances[0].pvalue
 from Bio.Cluster import distancematrix
 matrix = distancematrix(data)
 from numpy import array
 from Bio.Cluster import distancematrix
 data = array([[0, 1,  2,  3],
 distances = distancematrix(data, dist='e')
 distances
 from Bio.Cluster import clustercentroids
 cdata, cmask = clustercentroids(data)
 from Bio.Cluster import clusterdistance
 distance = clusterdistance(data)
 from Bio.Cluster import kcluster
 clusterid, error, nfound = kcluster(data)
 from Bio.Cluster import kmedoids
 clusterid, error, nfound = kmedoids(distance)
 from Bio.Cluster import Node
 Node(2, 3)
 Node(2, 3, 0.91)
 node = Node(4, 5)
 node.left = 6
 node.right = 2
 node.distance = 0.73
 node
 from Bio.Cluster import Node, Tree
 nodes = [Node(1, 2, 0.2), Node(0, 3, 0.5), Node(-2, 4, 0.6), Node(-1, -3, 0.
 tree = Tree(nodes)
 print(tree)
 nodes = [Node(1, 2, 0.2), Node(0, 2, 0.5)]
 Tree(nodes)
  File "<stdin", line 1, in ?
 nodes = [Node(1, 2, 0.2), Node(0, -1, 0.5)]
 tree = Tree(nodes)
 tree[0]
 tree[1]
 tree[-1]
 tree = Tree([Node(1, 2, 0.1), Node(0, -1, 0.5), Node(-2, 3, 0.9)])
 print(tree)
 nodes = tree[:]
 nodes[0] = Node(0, 1, 0.2)
 nodes[1].left = 2
 tree = Tree(nodes)
 print(tree)
 tree.scale()
 indices = tree.sort(order)
 clusterid = tree.cut(nclusters=1)
 from Bio.Cluster import treecluster
 tree = treecluster(data)
 from Bio.Cluster import treecluster
 tree = treecluster(distancematrix=distance)
 from Bio.Cluster import somcluster
 clusterid, celldata = somcluster(data)
 from Bio.Cluster import pca
 columnmean, coordinates, components, eigenvalues = pca(data)
 from Bio import Cluster
 with open("mydatafile.txt") as handle:
 import gzip # Python standard library
 handle = gzip.open("mydatafile.txt.gz", "rt")
 from urllib.request import urlopen
 from io import TextIOWrapper
 handle = TextIOWrapper(urlopen("https://raw.githubusercontent.com/biopython/
 matrix = record.distancematrix()
 cdata, cmask = record.clustercentroids()
 distance = record.clusterdistance()
 tree = record.treecluster()
 clusterid, error, nfound = record.kcluster()
 clusterid, celldata = record.somcluster()
 record.save(jobname, geneclusters, expclusters)
 from Bio import Cluster
 with open("cyano.txt") as handle:
 genetree = record.treecluster(method="s")
 genetree.scale()
 exptree = record.treecluster(dist="u", transpose=1)
 record.save("cyano_result", genetree, exptree)
 from Bio import Cluster
 with open("cyano.txt") as handle:
 (geneclusters, error, ifound) = record.kcluster(nclusters=5, npass=1000)
 (expclusters, error, ifound) = record.kcluster(nclusters=2, npass=100, trans
 record.save("cyano_result", geneclusters, expclusters)
 from Bio import LogisticRegression
 xs = [[-53, -200.78],
 ys = [1,
 model = LogisticRegression.train(xs, ys)
 model.beta
 def show_progress(iteration, loglikelihood):

 model = LogisticRegression.train(xs, ys, update_fn=show_progress)
 print("yxcE, yxcD:", LogisticRegression.classify(model, [6, -173.143442352])
 print("yxiB, yxiA:", LogisticRegression.classify(model, [309, -271.005880394
 q, p = LogisticRegression.calculate(model, [6, -173.143442352])
 print("class OP: probability =", p, "class NOP: probability =", q)
 q, p = LogisticRegression.calculate(model, [309, -271.005880394])
 print("class OP: probability =", p, "class NOP: probability =", q)
 for i in range(len(ys)):
 for i in range(len(ys)):
 from Bio import kNN
 k = 3
 model = kNN.train(xs, ys, k)
 x = [6, -173.143442352]
 print("yxcE, yxcD:", kNN.classify(model, x))
 x = [309, -271.005880394]
 print("yxiB, yxiA:", kNN.classify(model, x))
 def cityblock(x1, x2):
 x = [6, -173.143442352]
 print("yxcE, yxcD:", kNN.classify(model, x, distance_fn = cityblock))
 def weight(x1, x2):
 x = [6, -173.143442352]
 print("yxcE, yxcD:", kNN.classify(model, x, weight_fn = weight))
 x = [6, -173.143442352]
 weight = kNN.calculate(model, x)
 print("class OP: weight =", weight[0], "class NOP: weight =", weight[1])
 x = [117, -267.14]
 weight = kNN.calculate(model, x)
 print("class OP: weight =", weight[0], "class NOP: weight =", weight[1])
 for i in range(len(ys)):
 k = 3
 for i in range(len(ys)):
 from Bio.KEGG import Enzyme
 records = Enzyme.parse(open("ec_5.4.2.2.txt"))
 record = list(records)[0]
 record.classname
 record.entry
 from Bio.KEGG import Enzyme
 record = Enzyme.read(open("ec_5.4.2.2.txt"))
 record.classname
 record.entry
 from Bio.KEGG import REST
 from Bio.KEGG import Enzyme
 request = REST.kegg_get("ec:5.4.2.2")
 open("ec_5.4.2.2.txt", "w").write(request.read())
 records = Enzyme.parse(open("ec_5.4.2.2.txt"))
 record = list(records)[0]
 record.classname
 record.entry
/list/hsa:10458+ece:Z5100          - REST.kegg_list(["hsa:10458", "ece:Z5100"])
/find/compound/300-310/mol_weight  - REST.kegg_find("compound", "300-310", "mol
/get/hsa:10458+ece:Z5100/aaseq     - REST.kegg_get(["hsa:10458", "ece:Z5100"],
 from Bio import phenotype
 for record in phenotype.parse("Plates.csv", "pm-csv"):
     record["A02"]
 from Bio import phenotype
 record = list(phenotype.parse("Plates.csv", "pm-csv"))[-1]
 print(record[0, 1].id)
 print(record[0])
 print(record[:, 0])
 print(record[:3, :3])
 from Bio import phenotype
 record = list(phenotype.parse("Plates.csv", "pm-csv"))[-1]
 well = record["A02"]
 for time, signal in well:
 well[:10]
 well[63:64:0.083]
 well[9.55]
 well[63.33:73.33]
 corrected = record.subtract_control(control="A01")
 record["A01"][63]
 corrected["A01"][63]
 from Bio import phenotype
 record = list(phenotype.parse("Plates.csv", "pm-csv"))[-1]
 well = record["A02"]
 well.fit()
 print("Function fitted: %s" % well.model)
 for param in ["area", "average_height", "lag", "max", "min",
 phenotype.write(record, "out.json", "pm-json")
 from Bio import SeqIO
 original_rec = SeqIO.read("NC_005816.gb", "genbank")
 import random
 nuc_list = list(original_rec.seq)
 random.shuffle(nuc_list)  # acts in situ!
 from Bio.Seq import Seq
 from Bio.SeqRecord import SeqRecord
 shuffled_rec = SeqRecord(Seq("".join(nuc_list)),
    if min(rec.letter_annotations["phred_quality"]) = 20
        elif len_record - index - len_adaptor = min_len:
 from Bio.SeqIO import QualityIO
 help(QualityIO)
 from Bio import SeqIO
 fq_dict = SeqIO.index("SRR020192.fastq", "fastq")
 len(fq_dict)
 list(fq_dict.keys())[:4]
 fq_dict["SRR020192.23186"].seq
 from Bio import SeqIO
 SeqIO.convert("E3MFGYR02_random_10_reads.sff", "sff", "reads.fasta", "fasta"
 SeqIO.convert("E3MFGYR02_random_10_reads.sff", "sff", "reads.qual", "qual")
 SeqIO.convert("E3MFGYR02_random_10_reads.sff", "sff", "reads.fastq", "fastq"
 from Bio import SeqIO
 SeqIO.convert("E3MFGYR02_random_10_reads.sff", "sff-trim", "trimmed.fasta",
 SeqIO.convert("E3MFGYR02_random_10_reads.sff", "sff-trim", "trimmed.qual", "
 SeqIO.convert("E3MFGYR02_random_10_reads.sff", "sff-trim", "trimmed.fastq",
$ sffinfo -seq -notrim E3MFGYR02_random_10_reads.sff  reads.fasta
$ sffinfo -qual -notrim E3MFGYR02_random_10_reads.sff  reads.qual
$ sffinfo -seq -trim E3MFGYR02_random_10_reads.sff  trimmed.fasta
$ sffinfo -qual -trim E3MFGYR02_random_10_reads.sff  trimmed.qual
 from Bio.SeqIO import SffIO
 help(SffIO)
 from Bio import SeqIO
 record = SeqIO.read("NC_005816.fna", "fasta")
 table = 11
 min_pro_len = 100
 for strand, nuc in [(+1, record.seq), (-1, record.seq.reverse_complement())]
...             if len(pro) = min_pro_len:
                if aa_end - aa_start = min_protein_length:
 from Bio import SeqIO
 sizes = [len(rec) for rec in SeqIO.parse("ls_orchid.fasta", "fasta")]
 len(sizes), min(sizes), max(sizes)
 sizes
        if i = 50:
 print(my_pssm[1]["A"])
 from Bio import AlignIO
 filename = "protein.aln"
 alignment = AlignIO.read(filename, "clustal")
 observed_frequencies = alignment.substitutions
 observed_frequencies = observed_frequencies.select("DEHKR")
 print(observed_frequencies)
<BLANKLINE
 import numpy
 observed_frequencies /= numpy.sum(observed_frequencies)
 residue_frequencies = numpy.sum(observed_frequencies, 0)
 print(format(residue_frequencies, "%.4f"))
<BLANKLINE
 numpy.sum(residue_frequencies)
 expected_frequencies = numpy.dot(residue_frequencies[:, None], residue_frequ
 print(format(expected_frequencies, "%.4f"))
<BLANKLINE
 m = numpy.log2(observed_frequencies/expected_frequencies)
 print(m)
<BLANKLINE
 from Bio.Align import PairwiseAligner
 aligner = PairwiseAligner()
 aligner.substitution_matrix = m
 aligner.gap_score = -3.0
 alignments = aligner.align("DEHEK", "DHHKK")
 print(alignments[0])
<BLANKLINE
 print("%.2f" % alignments.score)
 score = m['D','D'] + m['E','H'] + m['H','H'] + m['E','K'] + m['K','K']
 print("%.2f" % score)
 from Bio.Seq import Seq
 s = Seq("ACGT")
 len(s)
 s == "ACGT"
 exp_freq_table = SubsMat._exp_freq_table_from_obs_freq(OFM)
 EFM = SubsMat._build_exp_freq_mat(OFM, exp_freq_table)
 from SubsMat import *
 ftab = FreqTable.FreqTable(my_frequency_dictionary, FreqTable.FREQ)
 ftab = FreqTable.FreqTable(my_count_dictionary, FreqTable.COUNT)
 ftab = FreqTable.read_count(open("myCountFile"))
 ftab = FreqTable.read_frequency(open("myFrequencyFile"))
 handle = open("m_cold.fasta", "r")
 handle.readline()
"gi|8332116|gb|BE037100.1|BE037100 MP14H09 MP Mesembryanthemum ...\n"
 my_info = "A string\n with multiple lines."
 print(my_info)
 from io import StringIO
 my_info_handle = StringIO(my_info)
 first_line = my_info_handle.readline()
 print(first_line)
<BLANKLINE
 second_line = my_info_handle.readline()
 print(second_line)
